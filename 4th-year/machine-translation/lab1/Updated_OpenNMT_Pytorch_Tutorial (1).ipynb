{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpgq2KISOHBo"
      },
      "source": [
        "# I created the OpenNMT Pytorch tutorial using Colab.\n",
        "\n",
        "***First Go to Runtime and  change the runtime type to GPU.***\n",
        "\n",
        "\n",
        "<br>\n",
        " Copyright Park Chanjun\n",
        "<br>\n",
        " Email: bcj1210@naver.com\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKrzegS2O1t3"
      },
      "source": [
        "# Git Clone\n",
        "First Git clone the OpenNMT source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-kDi11Xx5bs",
        "outputId": "45e6398c-1b73-401a-9651-853738b738f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNMT-py'...\n",
            "remote: Enumerating objects: 17656, done.\u001b[K\n",
            "remote: Counting objects: 100% (615/615), done.\u001b[K\n",
            "remote: Compressing objects: 100% (316/316), done.\u001b[K\n",
            "remote: Total 17656 (delta 365), reused 489 (delta 289), pack-reused 17041\u001b[K\n",
            "Receiving objects: 100% (17656/17656), 273.79 MiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (12673/12673), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TlIyXGzO61s"
      },
      "source": [
        "# Please install requirements.txt use by pip\n",
        "\n",
        "> Error : You must restart the runtime in order to use newly installed versions.<br>\n",
        "Solution : Click Restart Runtime => Redo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gq-o1qtyFR0",
        "outputId": "634e731e-cf7b-4e02-ffa0-60463860d5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-2.2.0-py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 410 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting flask\n",
            "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.3 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting tensorboard>=2.3\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 1.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchtext==0.5.0\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting waitress\n",
            "  Downloading waitress-2.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /home/stephen/.local/lib/python3.8/site-packages (from OpenNMT-py) (1.10.1)\n",
            "Requirement already satisfied: configargparse in /home/stephen/.local/lib/python3.8/site-packages (from OpenNMT-py) (1.5.3)\n",
            "Collecting pyonmttok<2,>=1.23; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
            "  Downloading pyonmttok-1.30.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2 MB 2.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from OpenNMT-py) (5.3.1)\n",
            "Collecting Werkzeug>=2.0\n",
            "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /home/stephen/.local/lib/python3.8/site-packages (from flask->OpenNMT-py) (8.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /home/stephen/.local/lib/python3.8/site-packages (from flask->OpenNMT-py) (3.0.3)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.5.0-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 2.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/stephen/.local/lib/python3.8/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.21.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (45.2.0)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 2.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.22.0)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 7.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.6.1)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 18.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /home/stephen/.local/lib/python3.8/site-packages (from torchtext==0.5.0->OpenNMT-py) (4.62.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 3.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /home/stephen/.local/lib/python3.8/site-packages (from torch>=1.6.0->OpenNMT-py) (4.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/stephen/.local/lib/python3.8/site-packages (from Jinja2>=3.0->flask->OpenNMT-py) (2.0.1)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.1.0)\n",
            "Installing collected packages: Werkzeug, itsdangerous, flask, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, grpcio, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, tensorboard-plugin-wit, absl-py, tensorboard, sentencepiece, torchtext, waitress, pyonmttok, OpenNMT-py\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.1\n",
            "    Uninstalling torchtext-0.11.1:\n",
            "      Successfully uninstalled torchtext-0.11.1\n",
            "Successfully installed OpenNMT-py-2.2.0 Werkzeug-2.0.2 absl-py-1.0.0 cachetools-5.0.0 flask-2.0.2 google-auth-2.5.0 google-auth-oauthlib-0.4.6 grpcio-1.43.0 itsdangerous-2.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyonmttok-1.30.1 requests-oauthlib-1.3.1 rsa-4.8 sentencepiece-0.1.96 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchtext-0.5.0 waitress-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_4ZgPbp71Eb"
      },
      "source": [
        "# Theory explanation\n",
        "\n",
        "**Machine translation is a field of natural language processing, meaning that computers translate one language into another.**\n",
        "\n",
        "Rule based, and statistical based, and recently we are using Deep Learning-based machine translation.\n",
        "\n",
        "Learn how to build a real machine translation system and how the system pipeline is structured. Most of these courses can be applied to basic natural language processing problems as well as machine translation.\n",
        "\n",
        "**Step**\n",
        "\n",
        "\n",
        "\n",
        "**1.   Data Collection**\n",
        "\n",
        "Parallel corpus is collected from various sources. It is possible to collect news texts, drama / movie subtitles, Wikipedia, etc., as well as data sets for evaluation of translation systems disclosed by WMT, a machine translation competition, and use them in translation systems.\n",
        "\n",
        "\n",
        "**2.   Cleaning**\n",
        "\n",
        "The collected data must be refined. The refinement process includes sorting sentences by corpus in both languages, and eliminating noise such as special characters.\n",
        "\n",
        "\n",
        "**3. Subword Tokenization**\n",
        "\n",
        "Refine spacing using the POS tagger or segmenter for each language. English may have refinement issues in upper / lower case.\n",
        "After the spacing is refined, use Byte Pair Encoding (BPE) using public tools such as Subword or WordPiece. This allows you to perform additional segments and construct a vocabulary list. At this time, the segmented models learned for the BPE segment should be kept for future use.\n",
        "\n",
        "\n",
        "**4. Train**\n",
        "\n",
        "Train the seq2seq model using prepared datasets. Depending on the amount, you can train with a single GPU, or use multiple GPUs in parallel to reduce training time.\n",
        "\n",
        "\n",
        "**5. Translate**\n",
        "\n",
        "Now that the model has been created, you can start translating.\n",
        "\n",
        "\n",
        "**6. Detokenization**\n",
        "\n",
        "Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.\n",
        "\n",
        "\n",
        "**7. Evaluating**\n",
        "\n",
        "Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRw9DCZ9n7h"
      },
      "source": [
        "# Tutotorial Start\n",
        "\n",
        "\n",
        "Assume that you have data collection and refinement and start the tutorial.\n",
        "\n",
        "Use the data provided by OpenNMT-py.\n",
        "\n",
        "Locate in **OpenNMT-py/data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTBNfRgW-WvJ"
      },
      "source": [
        "# Subword Tokenization\n",
        "\n",
        "We use Byte Pair Encoding for Subword Tokenization\n",
        "\n",
        "https://www.aclweb.org/anthology/P16-1162\n",
        "\n",
        "i => input<br>\n",
        "o ==> Output(*.code)<br>\n",
        "s ==> Symbol<br>\n",
        "\n",
        "learn_bpe ==> make code<br>\n",
        "apply_bpe ==> apply subwordTokenization<br>\n",
        "\n",
        "src-train, src-val,test ==> Need to apply src.code<br>\n",
        "tgt-train,tgt-val ==> Need to apply tgt.code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASorEhAu-kdM"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src.code -s 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBNAu8tR_GcV"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt.code -s 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB5FdD-H_H59"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src-train-bpe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaherUkX_IBg"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-val.txt -o OpenNMT-py/data/src-val-bpe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz7Xu72Y_mWW"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-test.txt -o OpenNMT-py/data/src-test-bpe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSGaSYgq_nmd"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt-train-bpe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7n68i95_nuJ"
      },
      "outputs": [],
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-val.txt -o OpenNMT-py/data/tgt-val-bpe.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FknMbLeePeoQ"
      },
      "source": [
        "# **Preprocess the data**\n",
        "\n",
        "We will be working with some example data in data/ folder.\n",
        "\n",
        "The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space:\n",
        "\n",
        "1. src-train.txt\n",
        "\n",
        "2. tgt-train.txt\n",
        "\n",
        "3. src-val.txt\n",
        "\n",
        "4. tgt-val.txt\n",
        "\n",
        "\n",
        "Train data and validataion data are required for machine translation training.\n",
        "\n",
        "Validation files are required and used to evaluate the convergence of the training. It usually contains no more than 5000 sentences.\n",
        "\n",
        "\n",
        "> If you think about it briefly, you can specify the path of train data and validation data, and specify the path and name to save in -save_data.\n",
        "\n",
        "> If you want to set vocab size add below command\n",
        "<br>\n",
        "-src_vocab_size 32000 -tgt_vocab_size 32000\n",
        "\n",
        "The vocab size is usually 32000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DrdI_6l0Kvw",
        "outputId": "a55faf5c-4c24-4f14-f34a-b85a19b05795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2022-01-25 15:25:14,821 INFO] Counter vocab from 10000 samples.\n",
            "[2022-01-25 15:25:14,821 INFO] Build vocab on 10000 transformed examples/corpus.\n",
            "[2022-01-25 15:25:14,836 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2022-01-25 15:25:14,837 WARNING] Empty line exists in corpus_1#4.\n",
            "[2022-01-25 15:25:15,243 INFO] Counters src:9911\n",
            "[2022-01-25 15:25:15,243 INFO] Counters tgt:10152\n"
          ]
        }
      ],
      "source": [
        "!python OpenNMT-py/build_vocab.py -config OpenNMT-py/demo-src-tgt.yml -n_sample 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isuv8jzcRMUA"
      },
      "source": [
        "# **Train the data(Basic)**\n",
        "\n",
        "This is simple Train command use 2-layer LSTM with 500 hidden units on both the encoder/decoder.\n",
        "\n",
        "If you want to use GPU , try add  below command (example use 2 GPU)\n",
        ">-world_size 2 -gpu_ranks 0 1\n",
        "\n",
        "Let's Check Available GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH1fS8F2VAuz",
        "outputId": "0de8852a-68ef-4b63-9ff1-137e7b3bff89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jan 25 15:24:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTeMhgJFb2iU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHlc5lBT15SH",
        "outputId": "d9db18b9-560f-482b-a36d-cc214237a33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/train.py\", line 2, in <module>\n",
            "    from onmt.bin.train import main\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/__init__.py\", line 2, in <module>\n",
            "    import onmt.inputters\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/inputters/__init__.py\", line 6, in <module>\n",
            "    from onmt.inputters.inputter import get_fields, build_vocab, filter_example\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/inputters/inputter.py\", line 109\n",
            "    raise ValueError(f\"No task specific tokens defined for {data_task}\")\n",
            "                                                                      ^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ],
      "source": [
        "!python OpenNMT-py/train.py -config OpenNMT-py/demo-src-tgt.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8wQov27R004"
      },
      "source": [
        "# **Train the data(Transformer)**\n",
        "\n",
        "https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "\n",
        "\n",
        "> If you get GPU-related errors, try halving batch_size\n",
        "\n",
        "**Below is the full command, and if you want to know more about it, search about Transformer.**\n",
        "\n",
        "!python OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer -decoder_type transformer -position_encoding -train_steps 200000 -max_generator_batches 2 -dropout 0.1 -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 -world_size 1 -gpu_rank 0  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdTjS0bTSVLk",
        "outputId": "d7f4d3a2-ea7a-4d6d-c6c3-55460376b330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-03-16 16:50:39,811 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
            "[2022-03-16 16:50:39,812 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2022-03-16 16:50:39,812 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2022-03-16 16:50:39,812 INFO] Parsed 2 corpora from -data.\n",
            "[2022-03-16 16:50:39,812 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2022-03-16 16:50:39,812 INFO] Loading vocab from text file...\n",
            "[2022-03-16 16:50:39,812 INFO] Loading src vocabulary from OpenNMT-py/data/demo.vocab.src\n",
            "[2022-03-16 16:50:39,835 INFO] Loaded src vocab has 9911 tokens.\n",
            "[2022-03-16 16:50:39,840 INFO] Loading tgt vocabulary from OpenNMT-py/data/demo.vocab.tgt\n",
            "[2022-03-16 16:50:39,861 INFO] Loaded tgt vocab has 10152 tokens.\n",
            "[2022-03-16 16:50:39,866 INFO] Building fields with vocab in counters...\n",
            "[2022-03-16 16:50:39,885 INFO]  * tgt vocab size: 10156.\n",
            "[2022-03-16 16:50:39,903 INFO]  * src vocab size: 9913.\n",
            "[2022-03-16 16:50:39,904 INFO]  * src vocab size = 9913\n",
            "[2022-03-16 16:50:39,904 INFO]  * tgt vocab size = 10156\n",
            "[2022-03-16 16:50:39,906 INFO] Building model...\n",
            "[2022-03-16 16:50:44,825 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(9913, 512, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10156, 512, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10156, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2022-03-16 16:50:44,828 INFO] encoder: 23990784\n",
            "[2022-03-16 16:50:44,828 INFO] decoder: 35635116\n",
            "[2022-03-16 16:50:44,828 INFO] * number of parameters: 59625900\n",
            "[2022-03-16 16:50:44,832 INFO] Starting training on GPU: [0]\n",
            "[2022-03-16 16:50:44,832 INFO] Start training loop and validate every 500 steps...\n",
            "[2022-03-16 16:50:44,833 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2022-03-16 16:50:44,833 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2022-03-16 16:50:44,833 WARNING] Empty line exists in corpus_1#4.\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/train.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/bin/train.py\", line 172, in main\n",
            "    train(opt)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/bin/train.py\", line 157, in train\n",
            "    train_process(opt, device_id=0)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/train_single.py\", line 109, in main\n",
            "    trainer.train(\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/trainer.py\", line 242, in train\n",
            "    self._gradient_accumulation(\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/trainer.py\", line 366, in _gradient_accumulation\n",
            "    outputs, attns = self.model(\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/models/model.py\", line 67, in forward\n",
            "    dec_out, attns = self.decoder(dec_in, memory_bank,\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/decoders/transformer.py\", line 466, in forward\n",
            "    output, attn, attn_align = layer(\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/decoders/transformer.py\", line 98, in forward\n",
            "    output, attns = self._forward(*args, **kwargs)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/decoders/transformer.py\", line 262, in _forward\n",
            "    query, _ = self._forward_self_attn(\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/decoders/transformer.py\", line 144, in _forward_self_attn\n",
            "    return self.self_attn(\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/modules/multi_headed_attn.py\", line 203, in forward\n",
            "    drop_attn = self.dropout(attn)\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/modules/dropout.py\", line 58, in forward\n",
            "    return F.dropout(input, self.p, self.training, self.inplace)\n",
            "  File \"/home/stephen/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 1169, in dropout\n",
            "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 5.94 GiB total capacity; 3.25 GiB already allocated; 105.12 MiB free; 3.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ],
      "source": [
        "!python3 OpenNMT-py/train.py -config OpenNMT-py/demo-transformer.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMf27BpGWpn7"
      },
      "source": [
        "# **Translate**\n",
        "\n",
        "Now that you have your model, you can start translating.\n",
        "\n",
        "-model ==> Setting your model\n",
        "\n",
        "Output predictions into pred.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqz9Iu7pW4Bq",
        "outputId": "65f83cad-7b8c-4a5d-895a-6ba6f1d17636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/translate.py\", line 2, in <module>\n",
            "    from onmt.bin.translate import main\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/__init__.py\", line 2, in <module>\n",
            "    import onmt.inputters\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/inputters/__init__.py\", line 6, in <module>\n",
            "    from onmt.inputters.inputter import get_fields, build_vocab, filter_example\n",
            "  File \"/home/stephen/Desktop/machine-translation-labs/lab1/OpenNMT-py/onmt/inputters/inputter.py\", line 109\n",
            "    raise ValueError(f\"No task specific tokens defined for {data_task}\")\n",
            "                                                                      ^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ],
      "source": [
        "!python OpenNMT-py/translate.py -model OpenNMT-py/model/model_step_1000.pt -src OpenNMT-py/data/src-test.txt -output OpenNMT-py/data/pred.txt -replace_unk -verbose -beam_size 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjG2ILxtGQ5U"
      },
      "source": [
        "# Detokenization\n",
        "\n",
        "Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.\n",
        "\n",
        "We Use \"sed\" for BPE Detokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74sox8UmGcbc"
      },
      "outputs": [],
      "source": [
        "!sed -i 's/\\@\\@ //g' OpenNMT-py/data/pred.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCHeu1YFGngg"
      },
      "source": [
        "# Evaluation Using BLEU\n",
        "\n",
        "Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing.\n",
        "\n",
        "https://www.aclweb.org/anthology/P02-1040"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gpcnSSTG0Kg",
        "outputId": "819d1701-15a7-4509-da82-8b98232c5f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR: could not find reference file OpenNMT-py/data/ref.txt at OpenNMT-py/tools/multi-bleu-detok.perl line 40.\n"
          ]
        }
      ],
      "source": [
        "# We don't have a reference file, but this command stays the same to get the bleu score for the translated sentences.\n",
        "\n",
        "#!perl  OpenNMT-py/tools/multi-bleu-detok.perl OpenNMT-py/data/ref.txt < OpenNMT-py/data/pred.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfAgvxNCXTo6"
      },
      "source": [
        "If you have Any Question Please Email to  \"bcj1210@naver.com\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of OpenNMT_Pytorch_Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
